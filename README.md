![_f7979ef0-741e-441f-b442-84fbe3c50f5c](https://github.com/frasertajima/kindle_clippings/assets/69366820/c5867780-b2e5-4ce7-a26c-b0a3b1bbde3c)

# kindle_clippings
Jupyter notebook to make your `My Clippings.txt` file automatically generated by the Kindle more useful. Due to changes in the Paperwhite file structure, `Kindle_my_clippings_reader.ipynb` can now handle both the Scribe and Paperwhite (and maybe other versions with updated firmware).

# getting started
1. copy the `Kindle_my_clippings_reader.ipynb` notebook to Colab by pressing the `Open in Colab` button.
2. connect your Kindle to your PC and navigate to your `/documents` folder. Copy the `My Clippings.txt` file to your Colab default directory.
3. copy the `blank.csv` file to the default Colab directory
4. run the notebook

# when you already have vocabulary words and definitions
Save them to a csv file called `2DoList.csv` with the csv format. Duplicate the csv format found in `Kindle_vocab.csv` (essentially WORD and DEFINITION) for your own vocabulary file. When re-running the Jupyter notebook you should then have your old words plus the new words from the Kindle clipping text file.

Note that the `Kindle_vocab_updated.csv` file will be the reference vocabulary file going forward. You can save this file or load it in other applications.

# oxford dictionary lookup.ipynb
Uses the Oxford Dictionary API to automatically lookup definitions for words saved in the Kindle vocabulary file. You will need to register for your free API key. Note that Oxford also imposes traffic limits on the number of definitions it can lookup in the free tier.

# suggested uses
Beside providing an automated method of updating your vocabulary database (with definitions using the `oxford dictionary lookup.ipyb` notebook), the Kindle clippings reader notebook provides an easy way to extract information from the Kindle clippings text file.
1. list all the books, pdfs and other sources you clipped from
2. search for words in specific sources or all sources, with detailed references as to when it was clipped and where. You can use two search terms. `Tesla | China` searches for Tesla **or** China while `Tesla .* China` searches for Tesla **and** China.
3. get an idea as to the distribution of your clipping lengths
4. get an overview of the topics covered and key words from your clippings

# LLM experiment
A convenient LLM found in OpenVINO was modified and was able to use the clippings dataframe as a local source for the language model. The OpenVINO performance was surprisingly good but the end results, while curious, are not production ready as they are basic at best. Still, the idea of tuning a LLM on local source text is interesting:
1. automatically gather text clippings while using the Kindle Scribe normally
2. run the `Kindle_my_clippings_reader.ipynb` notebook to automatically create and save a dataframe
3. load up a LLM notebook and use the dataframe columns (source and quotation) as local source text for fine tuning the LLM

With better and better LLM models, the performance of this workflow should improve. I describe a sample notebook modified from the OpenVINO example in the `local_llm_processing.ipynb` notebook as a first try in exploring the use of LLM in local source text processing.
